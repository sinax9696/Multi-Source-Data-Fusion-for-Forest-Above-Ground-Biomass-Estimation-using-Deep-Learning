{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-04 14:13:28.018229: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-04 14:13:28.041198: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-04 14:13:28.041221: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-04 14:13:28.041846: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-04 14:13:28.045924: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-04 14:13:28.465549: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import random\n",
    "from keras_unet_collection import models, base, utils\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "from keras import backend as K\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io  # for reading TIFF images\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, concatenate, Conv2DTranspose\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.losses import *\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the desired number of patches\n",
    "desired_num_patches = 1681\n",
    "\n",
    "# Your data directories\n",
    "optic_images_dir = 'Mosaic30m_patches_128px'\n",
    "sar_images_dir = 'SAR_patches_128px'\n",
    "agb_maps_dir = 'AGB128Pxpatches'\n",
    "fvs_images_dir = 'FVS_Patches'\n",
    "slope_images_dir = 'UNET_Slope_Patches/Patches'\n",
    "aspect_images_dir = 'UNET_Aspect_Patches'\n",
    "# Get the list of file names in the directories without sorting\n",
    "agb_map_files = os.listdir(agb_maps_dir)\n",
    "optic_image_files = os.listdir(optic_images_dir)\n",
    "sar_image_files = os.listdir(sar_images_dir)\n",
    "fvs_image_files = os.listdir(fvs_images_dir)\n",
    "slope_image_files = os.listdir(slope_images_dir)\n",
    "aspect_image_files = os.listdir(aspect_images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Patches: 100%|█████████▉| 1680/1681 [00:04<00:00, 365.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (1075, 128, 128, 24)\n",
      "y_train: (1075, 128, 128, 1)\n",
      "x_val: (269, 128, 128, 24)\n",
      "y_val: (269, 128, 128, 1)\n",
      "x_test: (337, 128, 128, 24)\n",
      "y_test: (337, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize empty lists to store data\n",
    "x_train_list = []\n",
    "y_train_list = []\n",
    "agb_values_list = []\n",
    "\n",
    "# Loop through each patch with tqdm for progress tracking\n",
    "for i in tqdm(range(min(desired_num_patches, len(optic_image_files))), desc='Loading Patches'):\n",
    "    # Get file names for the current index\n",
    "    optic_file = optic_image_files[i]\n",
    "    sar_file = sar_image_files[i]\n",
    "    agb_file = agb_map_files[i]\n",
    "    fvs_file = fvs_image_files[i]\n",
    "    slope_file = slope_image_files[i]  # New Slope file\n",
    "    aspect_file = aspect_image_files[i]  # New Aspect file\n",
    "    \n",
    "    # Load images\n",
    "    optic_image = io.imread(os.path.join(optic_images_dir, optic_file))\n",
    "    sar_image = io.imread(os.path.join(sar_images_dir, sar_file))\n",
    "    agb_map = io.imread(os.path.join(agb_maps_dir, agb_file))\n",
    "    fvs_image = io.imread(os.path.join(fvs_images_dir, fvs_file))  # Load FVS image\n",
    "    slope_image = io.imread(os.path.join(slope_images_dir, slope_file))  # Load Slope image\n",
    "    aspect_image = io.imread(os.path.join(aspect_images_dir, aspect_file))  # Load Aspect image\n",
    "\n",
    "    # Ensure the optic image has 13 bands\n",
    "    if optic_image.shape[-1] != 13:\n",
    "        raise ValueError(f\"Optic image should have 13 bands. Found: {optic_image.shape[-1]}\")\n",
    "    \n",
    "    # Ensure FVS image has 7 bands\n",
    "    if fvs_image.shape[-1] != 7:\n",
    "        raise ValueError(f\"FVS image should have 7 bands. Found: {fvs_image.shape[-1]}\")\n",
    "    \n",
    "    # Ensure Slope and Aspect images are 2D (single band)\n",
    "    if slope_image.ndim != 2 or aspect_image.ndim != 2:\n",
    "        raise ValueError(\"Slope and Aspect images should be 2D.\")\n",
    "    \n",
    "    # Normalize all datasets using min-max scaling\n",
    "    optic_image_normalized = (optic_image - np.min(optic_image)) / (np.max(optic_image) - np.min(optic_image))\n",
    "    sar_image_normalized = (sar_image - np.min(sar_image)) / (np.max(sar_image) - np.min(sar_image))\n",
    "    fvs_image_normalized = (fvs_image - np.min(fvs_image)) / (np.max(fvs_image) - np.min(fvs_image))\n",
    "    slope_image_normalized = (slope_image - np.min(slope_image)) / (np.max(slope_image) - np.min(slope_image))\n",
    "    aspect_image_normalized = (aspect_image - np.min(aspect_image)) / (np.max(aspect_image) - np.min(aspect_image))\n",
    "\n",
    "    # Expand the dimensions of Slope and Aspect to match the channel structure\n",
    "    slope_image_expanded = np.expand_dims(slope_image_normalized, axis=-1)\n",
    "    aspect_image_expanded = np.expand_dims(aspect_image_normalized, axis=-1)\n",
    "\n",
    "    # Concatenate optic, SAR, FVS, Slope, and Aspect images along the channel axis\n",
    "    x_train = np.concatenate([optic_image_normalized, sar_image_normalized, fvs_image_normalized, slope_image_expanded, aspect_image_expanded], axis=-1)\n",
    "\n",
    "    # Store the concatenated data\n",
    "    x_train_list.append(x_train)\n",
    "    agb_values_list.append(agb_map)\n",
    "\n",
    "    # Break the loop if the desired number of patches is reached\n",
    "    if len(x_train_list) >= desired_num_patches:\n",
    "        break\n",
    "\n",
    "# Combine all patches into single arrays\n",
    "x_data = np.stack(x_train_list)\n",
    "agb_values = np.stack(agb_values_list)\n",
    "\n",
    "# Normalize AGB values using min-max scaling\n",
    "min_agb = np.min(agb_values)\n",
    "max_agb = np.max(agb_values)\n",
    "agb_scaled = (agb_values - min_agb) / (max_agb - min_agb)\n",
    "\n",
    "# Reshape scaled AGB values for compatibility with the model\n",
    "agb_normalized = np.expand_dims(agb_scaled, axis=-1)\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, agb_normalized, test_size=0.20, random_state=42)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.20, random_state=42)\n",
    "\n",
    "# Print the shapes of the datasets to ensure they have the correct dimensions\n",
    "print('x_train:', x_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('x_val:', x_val.shape)\n",
    "print('y_val:', y_val.shape)\n",
    "print('x_test:', x_test.shape)\n",
    "print('y_test:', y_test.shape)\n",
    "\n",
    "input_shape = x_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = models.u2net_2d((128, 128, 24), n_labels=1, \n",
    "                        filter_num_down=[64, 128, 256, 512],\n",
    "                        activation='ReLU', output_activation='Sigmoid', \n",
    "                        batch_norm=True, pool=False, unpool=False, deep_supervision=True, name='u2net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.transunet_2d((512, 512, 3), filter_num=[64, 128, 256, 512], n_labels=1, stack_num_down=2, stack_num_up=2,\n",
    "                                embed_dim=128, num_mlp=2048, num_heads=12, num_transformer=12,\n",
    "                                activation='ReLU', mlp_activation='GELU', output_activation='Sigmoid', \n",
    "                                batch_norm=True, pool=True, unpool='bilinear', name='transunet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-5\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=10,\n",
    "                               min_lr=0.5e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelcheckpoint\n",
    "checkpointer = tf.keras.callbacks.ModelCheckpoint('model_for_TransUNET.h5',  monitor='val_mae' ,verbose=1, save_best_only=True)\n",
    "\n",
    "callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(patience=10, monitor='val_mae'),\n",
    "        tf.keras.callbacks.TensorBoard(log_dir='logs'),\n",
    "        checkpointer, lr_reducer, lr_scheduler]\n",
    "\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "results = model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=4, epochs=120, callbacks=callbacks)\n",
    "\n",
    "end_time = time.time()\n",
    "training_time_seconds = end_time - start_time\n",
    "training_time_minutes = training_time_seconds / 60\n",
    "\n",
    "print(\"Training completed in {:.2f} seconds ({:.2f} minutes)\".format(training_time_seconds, training_time_minutes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
